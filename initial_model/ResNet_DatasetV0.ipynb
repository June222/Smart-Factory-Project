{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUunj32AbuV6",
        "outputId": "bc123777-5730-4d7e-fe7f-21e089b4ed8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# 코랩에서 구글 드라이브 접근\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.models.resnet import BasicBlock\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import models, datasets\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import os"
      ],
      "metadata": {
        "id": "xM4vGepbg3Id"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SteelDataset(Dataset):\n",
        "    def __init__(self, csv_path, img_dir, transform=None):\n",
        "        self.data = pd.read_csv(csv_path)\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = os.path.join(self.img_dir, str(self.data.iloc[idx, 1]), self.data.iloc[idx, 0])\n",
        "        image = Image.open(img_name)\n",
        "        label = self.data.iloc[idx, 1] - 1  # Adjust label to start from 0\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "hY30ZcwSg2ur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 하이퍼파라미터 설정\n",
        "batch_size = 32\n",
        "learning_rate = 0.001\n",
        "num_classes = 4\n",
        "\n",
        "# 데이터 로드 및 전처리\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "train_dataset = SteelDataset(csv_path='/content/drive/MyDrive/졸업과제/severstal-steel-defect-detection/aug-train.csv',\n",
        "                              img_dir='/content/drive/MyDrive/졸업과제/working/aug_train/',\n",
        "                              transform=transform)\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "R4T8QkrfhCSy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNetSteelClassifier(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(ResNetSteelClassifier, self).__init__()\n",
        "        self.resnet = models.resnet18(pretrained=True)\n",
        "        num_features = self.resnet.fc.in_features\n",
        "        self.resnet.fc = nn.Linear(num_features, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.resnet(x)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = ResNetSteelClassifier(num_classes=4).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tv2xFCMEhoRD",
        "outputId": "48291413-7fc7-4fac-c43e-a894f5592e70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 61.6MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "num_epochs = 20\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    with tqdm(train_loader, unit=\"batch\") as t:\n",
        "        for images, labels in t:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "            t.set_postfix(loss=running_loss / (t.n + 1))\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVj5gnO_hpiQ",
        "outputId": "c427d4ca-b42a-4d8b-c8bf-0ed6958696f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [20:35<00:00,  9.88s/batch, loss=1.21]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/20], Loss: 1.2096\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [00:40<00:00,  3.07batch/s, loss=1.08]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/20], Loss: 1.0801\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [00:40<00:00,  3.12batch/s, loss=1.03]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/20], Loss: 1.0283\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [00:40<00:00,  3.12batch/s, loss=0.95]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/20], Loss: 0.9504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [00:41<00:00,  3.00batch/s, loss=0.921]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/20], Loss: 0.9211\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [00:39<00:00,  3.15batch/s, loss=0.934]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6/20], Loss: 0.9338\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [00:43<00:00,  2.88batch/s, loss=0.877]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [7/20], Loss: 0.8769\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [00:39<00:00,  3.14batch/s, loss=0.881]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [8/20], Loss: 0.8806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [00:42<00:00,  2.98batch/s, loss=0.871]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [9/20], Loss: 0.8706\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [00:40<00:00,  3.07batch/s, loss=0.845]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/20], Loss: 0.8446\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [00:39<00:00,  3.13batch/s, loss=0.839]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [11/20], Loss: 0.8391\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [00:40<00:00,  3.11batch/s, loss=0.865]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [12/20], Loss: 0.8652\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [00:42<00:00,  2.95batch/s, loss=0.824]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [13/20], Loss: 0.8236\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [00:40<00:00,  3.10batch/s, loss=0.805]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [14/20], Loss: 0.8051\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [00:40<00:00,  3.10batch/s, loss=0.811]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [15/20], Loss: 0.8114\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [00:41<00:00,  3.02batch/s, loss=0.795]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [16/20], Loss: 0.7945\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [00:40<00:00,  3.09batch/s, loss=0.783]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [17/20], Loss: 0.7830\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [00:39<00:00,  3.15batch/s, loss=0.798]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [18/20], Loss: 0.7980\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [00:39<00:00,  3.16batch/s, loss=0.787]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [19/20], Loss: 0.7874\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [00:41<00:00,  2.98batch/s, loss=0.771]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [20/20], Loss: 0.7712\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습된 모델 저장\n",
        "torch.save(model.state_dict(), '/content/drive/MyDrive/졸업과제/모델/resnet_model_epoch_20.pth')"
      ],
      "metadata": {
        "id": "mn9AMX-OjjHy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 평가\n",
        "model.eval()\n",
        "preds = []\n",
        "targets = []\n",
        "\n",
        "with torch.no_grad(), tqdm(train_loader, unit=\"batch\") as t:\n",
        "    for images, labels in t:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        targets.extend(labels.cpu().numpy())\n",
        "        preds.extend(predicted.cpu().numpy())\n",
        "        t.set_postfix(accuracy=accuracy_score(targets, preds))\n",
        "\n",
        "# 평가 지표 계산\n",
        "accuracy = accuracy_score(targets, preds)\n",
        "precision = precision_score(targets, preds, average='weighted')\n",
        "recall = recall_score(targets, preds, average='weighted')\n",
        "f1 = f1_score(targets, preds, average='weighted')\n",
        "\n",
        "print()\n",
        "print(\"Train\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcKyt7nQdI1m",
        "outputId": "0f8cccba-2d77-4b95-e8c5-a471375d3d42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [00:34<00:00,  3.67batch/s, accuracy=0.567]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train\n",
            "Accuracy: 0.5673\n",
            "Precision: 0.6002\n",
            "Recall: 0.5673\n",
            "F1 Score: 0.5698\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 테스트 데이터 로드 및 전처리\n",
        "test_dataset = SteelDataset(csv_path='/content/drive/MyDrive/졸업과제/severstal-steel-defect-detection/aug-test.csv',\n",
        "                              img_dir='/content/drive/MyDrive/졸업과제/working/aug-test/',\n",
        "                              transform=transform)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# 모델 평가 및 평가 지표 계산 (테스트 데이터)\n",
        "test_preds = []\n",
        "test_targets = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    with tqdm(test_loader, unit=\"batch\") as t:\n",
        "        for images, labels in t:\n",
        "            images = images.cuda()\n",
        "            labels = labels.cuda()\n",
        "\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            test_preds.extend(predicted.cpu().numpy())\n",
        "            test_targets.extend(labels.cpu().numpy())\n",
        "\n",
        "            t.set_postfix(test_accuracy=accuracy_score(test_targets, test_preds))\n",
        "\n",
        "# 평가 지표 계산 (테스트 데이터)\n",
        "test_accuracy = accuracy_score(test_targets, test_preds)\n",
        "test_precision = precision_score(test_targets, test_preds, average='weighted')\n",
        "test_recall = recall_score(test_targets, test_preds, average='weighted')\n",
        "test_f1 = f1_score(test_targets, test_preds, average='weighted')\n",
        "\n",
        "print()\n",
        "print(\"Test\")\n",
        "print(f\"Accuracy: {test_accuracy:.4f}\")\n",
        "print(f\"Precision: {test_precision:.4f}\")\n",
        "print(f\"Recall: {test_recall:.4f}\")\n",
        "print(f\"F1 Score: {test_f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9U8Q8r5cdOV5",
        "outputId": "8fc043ea-3372-4bf0-f750-fc31246f765c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 32/32 [05:41<00:00, 10.68s/batch, test_accuracy=0.549]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test\n",
            "Accuracy: 0.5490\n",
            "Precision: 0.5722\n",
            "Recall: 0.5490\n",
            "F1 Score: 0.5487\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 저장된 모델 불러와서 사용"
      ],
      "metadata": {
        "id": "lJBr9OewpBzB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 모델 아키텍처 정의 및 초기화\n",
        "model = ResNetSteelClassifier(num_classes=4)  # 예시로 사용한 모델 아키텍처로 초기화\n",
        "\n",
        "# 2. 저장한 모델 파라미터 불러오기\n",
        "saved_model_path = '/content/drive/MyDrive/졸업과제/모델/resnet_model_epoch_10.pth'\n",
        "model.load_state_dict(torch.load(saved_model_path))\n",
        "model.to(device)\n",
        "model.eval()  # 모델을 평가 모드로 설정\n",
        "\n",
        "# 3. 입력 데이터로 예측 수행\n",
        "input_image = ...  # 예측하고자 하는 이미지 데이터\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "input_tensor = transform(input_image).unsqueeze(0).to(device)  # 배치 차원 추가 및 디바이스 설정\n",
        "\n",
        "with torch.no_grad():\n",
        "    output = model(input_tensor)\n",
        "    _, predicted_class = torch.max(output, 1)\n",
        "\n",
        "predicted_class = predicted_class.item()\n",
        "print(f'Predicted class: {predicted_class}')"
      ],
      "metadata": {
        "id": "a9shTUHVpDs4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 직접 구현된 코드"
      ],
      "metadata": {
        "id": "HycXGSSnj7LW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ResNet 모델 정의\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, layers, num_classes=num_classes):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 64\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1):\n",
        "        layers = []\n",
        "        layers.append(block(self.in_planes, planes, stride))\n",
        "        self.in_planes = planes * block.expansion\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(block(self.in_planes, planes))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# ResNet 모델 인스턴스 생성 및 GPU로 이동\n",
        "model = ResNet(BasicBlock, [2, 2, 2, 2]).cuda()\n",
        "\n",
        "# 손실 함수와 옵티마이저 설정\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# 모델 학습\n",
        "for epoch in range(num_epochs):\n",
        "    for images, labels in train_loader:\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "print(\"Training finished!\")"
      ],
      "metadata": {
        "id": "FGMIijslj6ZE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}